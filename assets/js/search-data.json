{
  
    
        "post0": {
            "title": "Imports",
            "content": "This is the condensed version of the MNIST training single layer NN with SGD from the Fastai course . Define the path . Here we define the path where all the images can be found. This already contains both training and validation images . path = untar_data(URLs.MNIST_SAMPLE) Path.BASE_PATH = path . Create dataloader objects . define the paths for sevens and threes | open the images and place them in a tensor | create a stack of all threes and of all sevens | create a training x set including images of threes and sevens | create a training y set of labels of threes and sevens | create the dataset which includes x&#39;s and y&#39;s | create a dataloader object and define the batch size | . threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() three_tensors = [tensor(Image.open(o)) for o in threes] stacked_threes = torch.stack(three_tensors).float()/255 sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() seven_tensors = [tensor(Image.open(o)) for o in sevens] stacked_sevens = torch.stack(seven_tensors).float()/255 train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) dset = list(zip(train_x,train_y)) dl = DataLoader(dset, batch_size=256) . Now do the same thing for the validation data . valid_threes=(path/&#39;valid&#39;/&#39;3&#39;).ls().sorted() valid_three_tensors = [tensor(Image.open(o)) for o in valid_threes] valid_stacked_threes = torch.stack(valid_three_tensors).float()/255 valid_sevens=(path/&#39;valid&#39;/&#39;7&#39;).ls().sorted() valid_seven_tensors = [tensor(Image.open(o)) for o in valid_sevens] valid_stacked_sevens = torch.stack(valid_seven_tensors).float()/255 valid_x = torch.cat([valid_stacked_threes, valid_stacked_sevens]).view(-1, 28*28) valid_y = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) valid_dl = DataLoader(valid_dset, batch_size=256) . Define the initial weights and biases . First define a function init_params which takes in the dimenension, and defines them as differentiable values. | Then create a set of weights (28*28) and biases | . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() weights = init_params((28*28,1)) bias = init_params(1) #weights.grad.zero_() #bias.grad.zero_(); . Define functions for training . Batch_accuracy takes in a batch of outputs of the model, pushes them to be between 0 and 1 and compares them with the true answer. The ouput is the average of the right and wrong answers, and therefore isn&#39;t the same as the loss function. | validate_epoch for each batch. | linear1 takes in all images and outputs the linear transformation from the weights and biases. | sigmoid | mnist_loss takes in the predictions (outputs of the model) flattens them with the sigmoid and compares them to the targets. | calc_grad takes the predictions, calculates the losses and the gradients using backpropagation. These gradients are attached to all parameters which have been defined previously as differentiable. | train_epoch passes in images, and labels, with the model (linear model in this case) to calc_grad, and updates parameters with grad values. It then runs through all parameters and applies gradient descent using the learning rate. | . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) def linear1(xb): return xb@weights + bias def sigmoid(x): return 1/(1+torch.exp(-x)) def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() def calc_grad(xb, yb, model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . Run for 20 epochs . Define the parameters, and run 20 epochs of train_epoch with a linear model and a learning rate of 1. print out the accuracy using validate_epoch on the model. | . lr = 1. params = weights,bias for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) .",
            "url": "https://jonstraveladventures.github.io/blogposts/2020/09/08/mnist-minimal.html",
            "relUrl": "/2020/09/08/mnist-minimal.html",
            "date": " • Sep 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "",
            "url": "https://jonstraveladventures.github.io/blogposts/2020/09/08/Untitled.html",
            "relUrl": "/2020/09/08/Untitled.html",
            "date": " • Sep 8, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jonstraveladventures.github.io/blogposts/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jonstraveladventures.github.io/blogposts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jonstraveladventures.github.io/blogposts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}