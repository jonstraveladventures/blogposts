{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the condensed version of the MNIST training single layer NN with SGD from the Fastai course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the path\n",
    "\n",
    "Here we define the path where all the images can be found. This already contains both training and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloader objects\n",
    "- define the paths for sevens and threes\n",
    "- open the images and place them in a tensor\n",
    "- create a stack of all threes and of all sevens\n",
    "- create a training x set including images of threes and sevens\n",
    "- create a training y set of labels of threes and sevens\n",
    "- create the dataset which includes x's and y's\n",
    "- create a dataloader object and define the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "dset = list(zip(train_x,train_y))\n",
    "dl = DataLoader(dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the same thing for the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_threes=(path/'valid'/'3').ls().sorted()\n",
    "valid_three_tensors = [tensor(Image.open(o)) for o in valid_threes]\n",
    "valid_stacked_threes = torch.stack(valid_three_tensors).float()/255\n",
    "\n",
    "valid_sevens=(path/'valid'/'7').ls().sorted()\n",
    "valid_seven_tensors = [tensor(Image.open(o)) for o in valid_sevens]\n",
    "valid_stacked_sevens = torch.stack(valid_seven_tensors).float()/255\n",
    "\n",
    "valid_x = torch.cat([valid_stacked_threes, valid_stacked_sevens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the initial weights and biases\n",
    "- First define a function init_params which takes in the dimenension, and defines them as differentiable values.\n",
    "- Then create a set of weights (28*28) and biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "#weights.grad.zero_()\n",
    "#bias.grad.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions for training\n",
    "- Batch_accuracy takes in a batch of outputs of the model, pushes them to be between 0 and 1 and compares them with the true answer. The ouput is the average of the right and wrong answers, and therefore isn't the same as the loss function.\n",
    "- validate_epoch for each batch.\n",
    "- linear1 takes in all images and outputs the linear transformation from the weights and biases.\n",
    "- sigmoid\n",
    "- mnist_loss takes in the predictions (outputs of the model) flattens them with the sigmoid and compares them to the targets.\n",
    "- calc_grad takes the predictions, calculates the losses and the gradients using backpropagation. These gradients are attached to all parameters which have been defined previously as differentiable.\n",
    "- train_epoch passes in images, and labels, with the model (linear model in this case) to calc_grad, and updates parameters with grad values. It then runs through all parameters and applies gradient descent using the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def linear1(xb): return xb@weights + bias\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for 20 epochs\n",
    "- Define the parameters, and run 20 epochs of train_epoch with a linear model and a learning rate of 1. print out the accuracy using validate_epoch on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
